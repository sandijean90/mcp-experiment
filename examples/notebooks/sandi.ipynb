{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beeai Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things to add:  \n",
    "- adding re-act agent and transfering the websearch from a static step to a tool\n",
    "- summarizing the past searches and storing them in memory\n",
    "- adding voice input, output\n",
    "- adding api call as tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SearxSearchWrapper\n",
    "from pydantic import Field\n",
    "import requests\n",
    "\n",
    "from beeai_framework.backend.chat import ChatModel, ChatModelOutput, ChatModelStructureOutput\n",
    "from beeai_framework.backend.message import UserMessage\n",
    "from beeai_framework.template import PromptTemplate, PromptTemplateInput\n",
    "import traceback\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from beeai_framework.workflows.workflow import Workflow, WorkflowError\n",
    "from pydantic import InstanceOf\n",
    "from beeai_framework.backend.message import AssistantMessage, SystemMessage\n",
    "from beeai_framework.memory.unconstrained_memory import UnconstrainedMemory\n",
    "from beeai_framework.agents.react.agent import ReActAgent\n",
    "from beeai_framework.tools import Tool, tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.tools import TavilySearchResults  # Import LangChain Tavily tool\n",
    "from typing import Any\n",
    "\n",
    "from beeai_framework.agents.react.agent import ReActAgent\n",
    "from beeai_framework.agents.react.types import ReActAgentRunOutput\n",
    "from beeai_framework.backend.chat import ChatModel\n",
    "from beeai_framework.emitter.emitter import Emitter, EventMeta\n",
    "from beeai_framework.emitter.types import EmitterOptions\n",
    "from beeai_framework.memory.unconstrained_memory import UnconstrainedMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does .env exist? Yes\n"
     ]
    }
   ],
   "source": [
    "#Load Tavily API Key\n",
    "\n",
    "# Check if the file exists\n",
    "env_path = os.path.join(os.getcwd(), \".env\")\n",
    "print(f\"Does .env exist? {'Yes' if os.path.exists(env_path) else 'No'}\")\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatModel.from_name(\"ollama:granite3.1-dense:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Overall State\n",
    "class SearchAgentState(BaseModel):\n",
    "    question: str\n",
    "    websearch_query: str | None = None\n",
    "    search_results: str | None = None\n",
    "    answer: str | None = None\n",
    "    memory: InstanceOf[UnconstrainedMemory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SearchRAGInput only needed if you are running web search as a structured step in the workflow\n",
    "\n",
    "# #structured input for RAG Search Agent\n",
    "# class SearchRAGInput(BaseModel):\n",
    "#     question: str\n",
    "#     search_results: str\n",
    "# #prompt template for question + search results to generate final response\n",
    "# search_rag_template = PromptTemplate(\n",
    "#     PromptTemplateInput(\n",
    "#         schema=SearchRAGInput,\n",
    "#         template=\"\"\"Search results:\n",
    "# Question: {{question}}\n",
    "# Search Results: {{search_results}}\n",
    "# Provide a concise answer based on the search results provided. If the results are irrelevant or insufficient, say 'I don't know.' Avoid phrases such as 'According to the results...'.\"\"\",\n",
    "#     )\n",
    "# )\n",
    "\n",
    "#structured output for the web search terms used by generate_web_search_terms function\n",
    "class WebSearchQuery(BaseModel):\n",
    "    search_query: str = Field(description=\"The web search query.\")\n",
    "\n",
    "# class WebSearchResults(BaseModel):\n",
    "#     results: str = Field(description=\"The web search results from the tool call.\")\n",
    "\n",
    "#structured input for creating search terms step\n",
    "class QuestionInput(BaseModel):\n",
    "    question: str\n",
    "\n",
    "#prompt template to create search terms\n",
    "search_query_template = PromptTemplate(\n",
    "    PromptTemplateInput(\n",
    "        schema=QuestionInput,\n",
    "        template=\"\"\"Convert the following question into a concise, effective web search query using keywords and operators for accuracy.\n",
    "Question: {{question}}\"\"\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for the Re-ACT Agent Process\n",
    "\n",
    "# Observe the agent\n",
    "async def observer(emitter: Emitter) -> None:\n",
    "    emitter.on(\"*.*\", process_agent_events, EmitterOptions(match_nested=True))\n",
    "\n",
    "#process agent events\n",
    "async def process_agent_events(event_data: dict[str, Any], event_meta: EventMeta) -> None:\n",
    "    \"\"\"Process agent events and log appropriately\"\"\"\n",
    "\n",
    "    if event_meta.name == \"error\":\n",
    "        print(\"Agent ðŸ¤– : \", event_data[\"error\"])\n",
    "    elif event_meta.name == \"retry\":\n",
    "        print(\"Agent ðŸ¤– : \", \"retrying the action...\")\n",
    "    elif event_meta.name == \"update\":\n",
    "        print(f\"Agent({event_data['update']['key']}) ðŸ¤– : \", event_data[\"update\"][\"parsedValue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web search tool if not using tavily\n",
    "# search_tool = SearxSearchWrapper(searx_host=\"http://127.0.0.1:8888\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the tool using the `tool` decorator\n",
    "@tool\n",
    "def tavily_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform a web search for the latest and most relevant information available online.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to look up on the web which comes from the websearch_query.\n",
    "    \n",
    "    Returns:\n",
    "        str: The top search results based on the Tavily API.\n",
    "    \"\"\"\n",
    "    if not isinstance(query, str) or not query.strip():\n",
    "        raise ValueError(\"Invalid query input. Expected a non-empty string.\")\n",
    "\n",
    "    tool = TavilySearchResults(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=False,)\n",
    "\n",
    "    searchresults = tool.invoke({\"query\": query})\n",
    "    return searchresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP IN WORKFLOW\n",
    "async def generate_web_search_terms(state: SearchAgentState) -> str:\n",
    "    print(\"Step: \", \"generate_web_search_terms\")\n",
    "    # Generate a search query\n",
    "    prompt = search_query_template.render(QuestionInput(question=state.question))\n",
    "    response: ChatModelStructureOutput = await model.create_structure(\n",
    "        schema=WebSearchQuery, messages=[UserMessage(prompt)]\n",
    "    )\n",
    "    #add the assistant response to websearch_query in state \n",
    "    state.websearch_query = response.object[\"search_query\"]\n",
    "    return \"generate_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an inital system prompt to memory so that it is not empty when the process kicks off\n",
    "\n",
    "memory = UnconstrainedMemory()\n",
    "await memory.add(SystemMessage(content=\"You are an AI assistant. You have access to a web search tool to help you gather information about the codes and provide the user with accurate, up-to-date information. If you call the tavily_search_tool you use websearch_query from State as your search terms.\"))\n",
    "\n",
    "#STEP IN WORKFLOW\n",
    "async def generate_answer(state: SearchAgentState) -> str:\n",
    "    print(\"Step: \", \"generate_answer\")\n",
    "    \n",
    "    # Ensure we are passing the correct search query\n",
    "    if not isinstance(state.websearch_query, str) or not state.websearch_query.strip():\n",
    "        raise ValueError(\"websearch_query is invalid. Ensure it is a non-empty string.\")\n",
    "    \n",
    "\n",
    "    #create the agent\n",
    "    agent = ReActAgent(llm=model, tools=[tavily_search_tool], memory=UnconstrainedMemory())\n",
    "    \n",
    "    # Debugging\n",
    "    print(f\"Running agent with query: {state.websearch_query}\")\n",
    "    \n",
    "    #run the agent\n",
    "    result: ReActAgentRunOutput = await agent.run(prompt= state.websearch_query).observe(observer)\n",
    "\n",
    "    # Store answer in state\n",
    "    state.answer = result.get_text_content()\n",
    "\n",
    "    # Add response to memory\n",
    "    await state.memory.add(AssistantMessage(content=state.answer))\n",
    "    \n",
    "    return Workflow.END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing just the genrate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question='What are the latest trends in AI?' websearch_query='latest trends in quantum computing' search_results=None answer=None memory=<beeai_framework.memory.unconstrained_memory.UnconstrainedMemory object at 0x11c2fe0f0>\n"
     ]
    }
   ],
   "source": [
    "state = SearchAgentState(\n",
    "    question=\"What are the latest trends in AI?\",\n",
    "    websearch_query=\"latest trends in quantum computing\",\n",
    "    search_results=None,\n",
    "    answer=None,\n",
    "    memory=UnconstrainedMemory()\n",
    ")\n",
    "\n",
    "# Print the instance\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  generate_answer\n",
      "Running agent with query: latest trends in quantum computing\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Transition from 'thought' to 'tool_input' does not exist!\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Transition from 'thought' to 'tool_input' does not exist!\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Transition from 'thought' to 'tool_input' does not exist!\n",
      "Agent ðŸ¤– :  retrying the action...\n",
      "Agent(thought) ðŸ¤– :  I need to perform a web search for the latest trends in quantum computing using the Tavily Search Tool.\n",
      "\n",
      "Agent(tool_name) ðŸ¤– :  tavily_search_tool\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Value for 'tool_input' cannot be retrieved because its value does not adhere to the appropriate schema.\n",
      "Agent ðŸ¤– :  Maximal amount of global retries (1) has been reached.\n"
     ]
    },
    {
     "ename": "AgentError",
     "evalue": "Maximal amount of global retries (1) has been reached.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinePrefixParserError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:70\u001b[39m, in \u001b[36mdo_retry.<locals>.handler\u001b[39m\u001b[34m(attempt, remaining)\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(factor ** (attempt - \u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(attempt)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:121\u001b[39m, in \u001b[36mRetryable.get.<locals>._retry\u001b[39m\u001b[34m(attempt)\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handlers.on_retry(ctx, last_error)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handlers.executor(ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/agents/react/runners/default/runner.py:197\u001b[39m, in \u001b[36mDefaultRunner.llm.<locals>.executor\u001b[39m\u001b[34m(_)\u001b[39m\n\u001b[32m    191\u001b[39m output: ChatModelOutput = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._input.llm.create(\n\u001b[32m    192\u001b[39m     messages=\u001b[38;5;28mself\u001b[39m.memory.messages[:],\n\u001b[32m    193\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    194\u001b[39m     tools=\u001b[38;5;28mself\u001b[39m._input.tools \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_native_tool_calling \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    195\u001b[39m ).observe(\u001b[38;5;28;01mlambda\u001b[39;00m llm_emitter: llm_emitter.on(\u001b[33m\"\u001b[39m\u001b[33mnewToken\u001b[39m\u001b[33m\"\u001b[39m, on_new_token))\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m parser.end()\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory.delete_many(\n\u001b[32m    200\u001b[39m     [\n\u001b[32m    201\u001b[39m         msg\n\u001b[32m   (...)\u001b[39m\u001b[32m    204\u001b[39m     ]\n\u001b[32m    205\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/parsers/line_prefix.py:227\u001b[39m, in \u001b[36mLinePrefixParser.end\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._emit_partial_update(\n\u001b[32m    225\u001b[39m         LinePrefixParserUpdate(key=\u001b[38;5;28mself\u001b[39m.last_node_key, value=field.get_partial(), delta=stash, field=field)\n\u001b[32m    226\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._emit_final_update(\u001b[38;5;28mself\u001b[39m.last_node_key, field)\n\u001b[32m    228\u001b[39m current_node = \u001b[38;5;28mself\u001b[39m.nodes[\u001b[38;5;28mself\u001b[39m.last_node_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/parsers/line_prefix.py:261\u001b[39m, in \u001b[36mLinePrefixParser._emit_final_update\u001b[39m\u001b[34m(self, key, field)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError:\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mthrow_with_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mValue for \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m cannot be retrieved because its value does not adhere to the appropriate schema.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mLinePrefixParserError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReason\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInvalidSchema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/parsers/line_prefix.py:198\u001b[39m, in \u001b[36mLinePrefixParser.throw_with_context\u001b[39m\u001b[34m(self, message, reason, extra)\u001b[39m\n\u001b[32m    197\u001b[39m full_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe generated output does not adhere to the schema.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m LinePrefixParserError(full_message, reason=reason, context=context)\n",
      "\u001b[31mLinePrefixParserError\u001b[39m: The generated output does not adhere to the schema.\nValue for 'tool_input' cannot be retrieved because its value does not adhere to the appropriate schema.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAgentError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m generate_answer(state=state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mgenerate_answer\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent with query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate.websearch_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#run the agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m result: ReActAgentRunOutput = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(prompt= state.websearch_query).observe(observer)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Store answer in state\u001b[39;00m\n\u001b[32m     25\u001b[39m state.answer = result.get_text_content()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/context.py:75\u001b[39m, in \u001b[36mRun._run_tasks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ensure_async(fn)(param)\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m.tasks.clear()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/context.py:171\u001b[39m, in \u001b[36mRunContext.enter.<locals>.handler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    169\u001b[39m     error = FrameworkError.ensure(e)\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m emitter.emit(\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m: error})\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m emitter.emit(\u001b[33m\"\u001b[39m\u001b[33mfinish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/context.py:158\u001b[39m, in \u001b[36mRunContext.enter.<locals>.handler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    155\u001b[39m runner_task = asyncio.create_task(_context_storage_run(), name=\u001b[33m\"\u001b[39m\u001b[33mrun-task\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    157\u001b[39m done, pending = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait([abort_task, runner_task], return_when=asyncio.FIRST_COMPLETED)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m result = \u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m abort_task.cancel()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m pending:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/context.py:138\u001b[39m, in \u001b[36mRunContext.enter.<locals>.handler.<locals>._context_storage_run\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_context_storage_run\u001b[39m() -> R:\n\u001b[32m    137\u001b[39m     RunContext.storage.set(context)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/agents/base.py:50\u001b[39m, in \u001b[36mBaseAgent.run.<locals>.handler\u001b[39m\u001b[34m(context)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(context: RunContext) -> T:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run({\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt}, {\u001b[33m\"\u001b[39m\u001b[33mexecution\u001b[39m\u001b[33m\"\u001b[39m: execution, \u001b[33m\"\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m\"\u001b[39m: signal}, context)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     52\u001b[39m         \u001b[38;5;28mself\u001b[39m.is_running = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/agents/react/agent.py:139\u001b[39m, in \u001b[36mReActAgent._run\u001b[39m\u001b[34m(self, run_input, options, context)\u001b[39m\n\u001b[32m    137\u001b[39m final_message: Message | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m final_message:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     iteration: ReActAgentRunnerIteration = \u001b[38;5;28;01mawait\u001b[39;00m runner.create_iteration()\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m iteration.state.tool_name \u001b[38;5;129;01mand\u001b[39;00m iteration.state.tool_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    142\u001b[39m         iteration.state.final_answer = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/agents/react/runners/base.py:109\u001b[39m, in \u001b[36mBaseRunner.create_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent was not able to resolve the task in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_iterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m iterations.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m emitter = \u001b[38;5;28mself\u001b[39m._run.emitter.child(group_id=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`iteration-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta.iteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m iteration = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm(ReActAgentRunnerLLMInput(emitter=emitter, signal=\u001b[38;5;28mself\u001b[39m._run.signal, meta=meta))\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._iterations.append(iteration)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ReActAgentRunnerIteration(emitter=emitter, state=iteration.state, meta=meta, signal=\u001b[38;5;28mself\u001b[39m._run.signal)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/agents/react/runners/default/runner.py:216\u001b[39m, in \u001b[36mDefaultRunner.llm\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     max_retries = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m Retryable(\n\u001b[32m    217\u001b[39m     RetryableInput(\n\u001b[32m    218\u001b[39m         on_retry=on_retry,\n\u001b[32m    219\u001b[39m         on_error=on_error,\n\u001b[32m    220\u001b[39m         executor=executor,\n\u001b[32m    221\u001b[39m         \u001b[38;5;66;03m# we need to handle empty results from LiteLLM\u001b[39;00m\n\u001b[32m    222\u001b[39m         config=RetryableConfig(max_retries=\u001b[38;5;28mmax\u001b[39m(max_retries, \u001b[32m1\u001b[39m), signal=\u001b[38;5;28minput\u001b[39m.signal),\n\u001b[32m    223\u001b[39m     )\n\u001b[32m    224\u001b[39m ).get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:148\u001b[39m, in \u001b[36mRetryable.get\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    138\u001b[39m     assert_aborted()\n\u001b[32m    140\u001b[39m options = {\n\u001b[32m    141\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mretries\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._config.max_retries,\n\u001b[32m    142\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfactor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._config.factor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mon_failed_attempt\u001b[39m\u001b[33m\"\u001b[39m: _on_failed_attempt,\n\u001b[32m    146\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m do_retry(_retry, options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:89\u001b[39m, in \u001b[36mdo_retry\u001b[39m\u001b[34m(fn, options)\u001b[39m\n\u001b[32m     85\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     87\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m handler(attempt + \u001b[32m1\u001b[39m, remaining - \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m abort_signal_handler(\u001b[38;5;28;01mlambda\u001b[39;00m: handler(\u001b[32m1\u001b[39m, options.get(\u001b[33m\"\u001b[39m\u001b[33mretries\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m)), options.get(\u001b[33m\"\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/cancellation.py:109\u001b[39m, in \u001b[36mabort_signal_handler\u001b[39m\u001b[34m(fn, signal, on_abort)\u001b[39m\n\u001b[32m    106\u001b[39m         signal.add_event_listener(abort_handler)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signal:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:87\u001b[39m, in \u001b[36mdo_retry.<locals>.handler\u001b[39m\u001b[34m(attempt, remaining)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (options.get(\u001b[33m\"\u001b[39m\u001b[33mshould_retry\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28;01mFalse\u001b[39;00m)(e)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m handler(attempt + \u001b[32m1\u001b[39m, remaining - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:79\u001b[39m, in \u001b[36mdo_retry.<locals>.handler\u001b[39m\u001b[34m(attempt, remaining)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options[\u001b[33m\"\u001b[39m\u001b[33mon_failed_attempt\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m options[\u001b[33m\"\u001b[39m\u001b[33mon_failed_attempt\u001b[39m\u001b[33m\"\u001b[39m](e, meta)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0\u001b[39m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/retryable.py:135\u001b[39m, in \u001b[36mRetryable.get.<locals>._on_failed_attempt\u001b[39m\u001b[34m(e, meta)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m last_error\n\u001b[32m    134\u001b[39m last_error = e\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handlers.on_error(e, \u001b[38;5;28mself\u001b[39m._get_context(meta.attempt))\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m FrameworkError.is_retryable(e):\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/agents/react/runners/default/runner.py:129\u001b[39m, in \u001b[36mDefaultRunner.llm.<locals>.on_error\u001b[39m\u001b[34m(error, _)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_error\u001b[39m(error: \u001b[38;5;167;01mException\u001b[39;00m, _: RetryableContext) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28minput\u001b[39m.emitter.emit(\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m: error, \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m.meta})\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_failed_attempts_counter\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, LinePrefixParserError):\n\u001b[32m    132\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m error.reason == LinePrefixParserError.Reason.NoDataReceived:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/utils/counter.py:43\u001b[39m, in \u001b[36mRetryCounter.use\u001b[39m\u001b[34m(self, error)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.remaining < \u001b[32m0\u001b[39m:\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m._finalError = \u001b[38;5;28mself\u001b[39m._error_class(\n\u001b[32m     41\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMaximal amount of global retries (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._max_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has been reached.\u001b[39m\u001b[33m\"\u001b[39m, cause=\u001b[38;5;28mself\u001b[39m._lastError\n\u001b[32m     42\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finalError\n",
      "\u001b[31mAgentError\u001b[39m: Maximal amount of global retries (1) has been reached."
     ]
    }
   ],
   "source": [
    "await generate_answer(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only use this step if you want to make the websearch a structured part of the workflow, not if you want to give the option for the agent to call websearch as a tool\n",
    "\n",
    "# async def execute_web_search(state: SearchAgentState) -> str:\n",
    "#     print(\"Step: \", \"execute_web_search\")\n",
    "\n",
    "#     if not state.websearch_query:\n",
    "#         print(\"No web search query generated.\")\n",
    "#         state.search_results = \"No search results available.\"\n",
    "#         return \"generate_answer\"\n",
    "\n",
    "#     try:\n",
    "#         # Perform web search\n",
    "#         state.search_results = str(search_tool.run(state.websearch_query))\n",
    "#     except Exception as e:\n",
    "#         print(\"Search tool failed! Agent will answer from memory.\")\n",
    "#         state.search_results = \"No search results available.\"\n",
    "\n",
    "#     return \"generate_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD GENRATE ANSWER FOR STRUCTURED WORKFLOW\n",
    "\n",
    "# async def generate_answer(state: SearchAgentState) -> str:\n",
    "#     print(\"Step: \", \"generate_answer\")\n",
    "\n",
    "#     # Generate response based on search results\n",
    "#     prompt = search_rag_template.render(\n",
    "#         SearchRAGInput(question=state.question, search_results=state.search_results or \"No results available.\")\n",
    "#     )\n",
    "#     # Add prompt to memory\n",
    "#     await state.memory.add(UserMessage(content=prompt))\n",
    "#     # Generate model output\n",
    "#     output: ChatModelOutput = await model.create(messages=state.memory.messages)\n",
    "#     # Store answer in state\n",
    "#     state.answer = output.get_text_content()\n",
    "#     # Add response to memory\n",
    "#     await state.memory.add(AssistantMessage(content=state.answer))\n",
    "#     return Workflow.END\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an inital system prompt to memory so that it is not empty when the process kicks off\n",
    "\n",
    "memory = UnconstrainedMemory()\n",
    "await memory.add(SystemMessage(content=\"You are an AI assistant that helps people understand their medical bills. You have access to a web search tool to help you gather information about the codes and provide the user with accurate, up-to-date information.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  generate_web_search_terms\n",
      "Step:  generate_answer\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Transition from 'thought' to 'tool_input' does not exist!\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Transition from 'thought' to 'tool_input' does not exist!\n",
      "Agent ðŸ¤– :  The generated output does not adhere to the schema.\n",
      "Transition from 'thought' to 'tool_input' does not exist!\n",
      "Agent ðŸ¤– :  retrying the action...\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m memory.add(UserMessage(content=user_input))\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Run workflow with memory\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m search_workflow.run(SearchAgentState(question=user_input, memory=memory))\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Print assistant response\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAssistant:\u001b[39m\u001b[33m\"\u001b[39m, response.state.answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/context.py:75\u001b[39m, in \u001b[36mRun._run_tasks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ensure_async(fn)(param)\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m.tasks.clear()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/site-packages/beeai_framework/context.py:157\u001b[39m, in \u001b[36mRunContext.enter.<locals>.handler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    151\u001b[39m abort_task = asyncio.create_task(\n\u001b[32m    152\u001b[39m     _context_signal_aborted(),\n\u001b[32m    153\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mabort-task\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m )\n\u001b[32m    155\u001b[39m runner_task = asyncio.create_task(_context_storage_run(), name=\u001b[33m\"\u001b[39m\u001b[33mrun-task\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m done, pending = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait([abort_task, runner_task], return_when=asyncio.FIRST_COMPLETED)\n\u001b[32m    158\u001b[39m result = done.pop().result()\n\u001b[32m    159\u001b[39m abort_task.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/asyncio/tasks.py:464\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing coroutines is forbidden, use tasks explicitly.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    463\u001b[39m loop = events.get_running_loop()\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/beeai/lib/python3.12/asyncio/tasks.py:550\u001b[39m, in \u001b[36m_wait\u001b[39m\u001b[34m(fs, timeout, return_when, loop)\u001b[39m\n\u001b[32m    547\u001b[39m     f.add_done_callback(_on_completion)\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ðŸ¤– :  Context destroyed.\n",
      "Agent ðŸ¤– :  Context destroyed.\n",
      "Agent(thought) ðŸ¤– :  I need to find out about India's history, culture, economy, geography, population, major cities, tourist attractions using the Tavily search tool.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UNSTRUCTURED WORKFLOW\n",
    "try:\n",
    "    search_workflow = Workflow(SearchAgentState)\n",
    "    \n",
    "    # Define workflow steps\n",
    "    search_workflow.add_step(\"generate_web_search_terms\", generate_web_search_terms)\n",
    "    search_workflow.add_step(\"generate_answer\", generate_answer)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User (type 'exit' to stop): \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Add user message to memory\n",
    "        await memory.add(UserMessage(content=user_input))\n",
    "\n",
    "        # Run workflow with memory\n",
    "        response = await search_workflow.run(SearchAgentState(question=user_input, memory=memory))\n",
    "        # Print assistant response\n",
    "        print(\"Assistant:\", response.state.answer)\n",
    "\n",
    "except WorkflowError:\n",
    "    traceback.print_exc()\n",
    "except ValidationError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Workflow Definition\n",
    "# try:\n",
    "#     search_workflow = Workflow(SearchAgentState)\n",
    "    \n",
    "#     # Define workflow steps\n",
    "#     search_workflow.add_step(\"generate_web_search_terms\", generate_web_search_terms)\n",
    "#     search_workflow.add_step(\"execute_web_search\", execute_web_search)\n",
    "#     search_workflow.add_step(\"generate_answer\", generate_answer)\n",
    "\n",
    "#     while True:\n",
    "#         user_input = input(\"User (type 'exit' to stop): \")\n",
    "#         if user_input.lower() == \"exit\":\n",
    "#             break\n",
    "\n",
    "#         # Add user message to memory\n",
    "#         await memory.add(UserMessage(content=user_input))\n",
    "\n",
    "#         # Run workflow with memory\n",
    "#         response = await search_workflow.run(SearchAgentState(question=user_input, memory=memory))\n",
    "\n",
    "#         # Print assistant response\n",
    "#         print(\"Assistant:\", response.state.answer)\n",
    "\n",
    "# except WorkflowError:\n",
    "#     traceback.print_exc()\n",
    "# except ValidationError:\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SearchAgentState.websearch_query = \"latest trends in quantum computing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the agent with a language model and the Tavily tool\n",
    "chat_model: ChatModel = ChatModel.from_name(\"ollama:granite3.1-dense:2b\")\n",
    "agent = ReActAgent(llm=chat_model, tools=[tavily_search_tool], memory=UnconstrainedMemory())\n",
    "\n",
    "# Run a query using the agent\n",
    "result = await agent.run(\"What are the latest advancements in quantum computing?\").observe(observer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beeai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
